{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                     #Load libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('movie_metadata.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.groupby(by = 'color')['color'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['color'] = dataset['color'].fillna('Color')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.groupby(by = 'color')['color'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = dataset[~dataset['duration'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_mean = dataset['duration'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration['duration'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['duration'] = dataset['duration'].fillna(duration_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['duration'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['num_critic_for_reviews'] = dataset['num_critic_for_reviews'].fillna(0)\n",
    "dataset['director_facebook_likes'] = dataset['director_facebook_likes'].fillna(0) \n",
    "dataset['actor_1_facebook_likes'] = dataset['actor_1_facebook_likes'].fillna(0)\n",
    "dataset['actor_2_facebook_likes'] = dataset['actor_2_facebook_likes'].fillna(0)\n",
    "dataset['actor_3_facebook_likes'] = dataset['actor_3_facebook_likes'].fillna(0)\n",
    "dataset['facenumber_in_poster'] = dataset['facenumber_in_poster'].fillna(0)\n",
    "dataset['num_user_for_reviews'] = dataset['num_user_for_reviews'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.groupby('language')['language'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['language'] = dataset['language'].fillna('English')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['country'] = dataset['country'].fillna('USA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, re\n",
    "def link_replacer(link):             \n",
    "    link = link.replace('http://www.movie.com/title/', 'https://www.imdb.com/title/')\n",
    "    link = link.replace('/?ref_=fn_tt_tt_1', '/')\n",
    "    return link\n",
    "\n",
    "\n",
    "def budget_extractor(link):           \n",
    "    \n",
    "    print(link)\n",
    "    r = requests.get(link)\n",
    "    if re.search('<h4 class=\"inline\">Budget:</h4>(.*?)<span class=\"attribute\">',r.text, re.DOTALL) is None:\n",
    "        return np.NAN\n",
    "    content = re.search('<h4 class=\"inline\">Budget:</h4>(.*?)<span class=\"attribute\">',r.text,re.DOTALL).group(1)\n",
    "    content = re.sub('\\W+','', content)\n",
    "    content = re.search(r'\\d+', content).group()\n",
    "    content = int(content)\n",
    "    return content\n",
    "\n",
    "\n",
    "def gross_extractor(link):         \n",
    "    print(link)\n",
    "    r = requests.get(link)\n",
    "    if re.search('<h4 class=\"inline\">Gross USA:</h4>(.*?)</div>',r.text, re.DOTALL) is None:\n",
    "                                                    #Check if Gross USA values exists\n",
    "        if re.search('<h4 class=\"inline\">Cumulative Worldwide Gross:</h4>(.*?)</div>',r.text, re.DOTALL) is None:\n",
    "            return np.NAN                       #Check if Cummulative Gross values exists\n",
    "        else:\n",
    "            content = re.search('<h4 class=\"inline\">Cumulative Worldwide Gross:</h4>(.*?)</div>',r.text,re.DOTALL).group(1)\n",
    "            content = re.sub('\\W+','', content)\n",
    "            content = re.search(r'\\d+', content).group()\n",
    "            content = int(content)\n",
    "            return content\n",
    "    else:\n",
    "        content = re.search('<h4 class=\"inline\">Gross USA:</h4>(.*?)</div>',r.text,re.DOTALL).group(1)\n",
    "        content = re.sub('\\W+','', content)\n",
    "        content = re.search(r'\\d+', content).group()\n",
    "        content = int(content)\n",
    "        return content\n",
    "dataset['movie_imdb_link'] = dataset['movie_imdb_link'].apply(lambda x: link_replacer(x))\n",
    "\n",
    "\n",
    "dataset['gross'] = dataset['movie_imdb_link'].apply(lambda x: gross_extractor(x))\n",
    "\n",
    "\n",
    "\n",
    "dataset['budget'] = dataset['movie_imdb_link'].apply(lambda x: budget_extractor(x))\n",
    "\n",
    "\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[~dataset['title_year'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(['director_name','actor_2_name','actor_1_name','movie_title','actor_3_name','plot_keywords','movie_imdb_link','title_year','aspect_ratio'], axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_content_rating = dataset[\"content_rating\"].value_counts()[:3].index\n",
    "dataset['content_rating'] = dataset.content_rating.where(dataset.content_rating.isin(top3_content_rating), 'other')\n",
    "dataset = pd.get_dummies(dataset, columns=['content_rating'], prefix = ['content_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_country = dataset[\"country\"].value_counts()[:3].index\n",
    "dataset['country'] = dataset.country.where(dataset.country.isin(top3_country), 'other')\n",
    "dataset = pd.get_dummies(dataset, columns=['country'], prefix = ['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top3_language = dataset[\"language\"].value_counts()[:3].index\n",
    "dataset['language'] = dataset.language.where(dataset.language.isin(top3_language), 'other')\n",
    "dataset = pd.get_dummies(dataset, columns=['language'], prefix = ['language'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.get_dummies(dataset, columns=['color'],prefix=['color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = dataset.corr()\n",
    "plt.figure(figsize = (12,12))\n",
    "sns.heatmap(corr_matrix, annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['actors_facebook_likes']=dataset['actor_1_facebook_likes']+dataset['actor_2_facebook_likes']+dataset['actor_3_facebook_likes']\n",
    "dataset=dataset.drop(columns=['actor_1_facebook_likes','actor_2_facebook_likes','actor_3_facebook_likes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = dataset.corr()\n",
    "plt.figure(figsize = (12,12))\n",
    "sns.heatmap(corr_matrix, annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop('actors_facebook_likes',axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = dataset.corr()\n",
    "plt.figure(figsize = (12,12))\n",
    "sns.heatmap(corr_matrix, annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop('genres', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.drop(columns=['imdb_score'])\n",
    "X\n",
    "y = dataset['imdb_score']\n",
    "y\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "y.shape\n",
    "#from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "#scaler_x = StandardScaler()\n",
    "#X = scaler_x.fit_transform(X)\n",
    "#scaler_y = StandardScaler()\n",
    "#y = scaler_x.fit_transform(y)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "RandomForest_model = RandomForestRegressor(n_estimators = 200)\n",
    "RandomForest_model.fit(X_train, y_train)\n",
    "accuracy_RandomForest = RandomForest_model.score(X_test, y_test)\n",
    "accuracy_RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=RandomForest_model.predict(X_test)\n",
    "print(\"Final rmse value is =\",np.sqrt(np.mean((y_test-y_pred)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
